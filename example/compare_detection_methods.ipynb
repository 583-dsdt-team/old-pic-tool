{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd10a44",
   "metadata": {},
   "source": [
    "# Compare two methods of assessing skin tone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4cbdc",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the **preprocess** and **detection** functions to implement two methods of assessing skin tone in black & white photos -- then, use **conf_matrix**, **mse**, and **OTHER FIT MODULES**? to assess which one worked better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99ad4a",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2944fe3",
   "metadata": {},
   "source": [
    "First, import relevant dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a86bd56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elizabethpelletier/tonelocator\n",
      "/Users/elizabethpelletier\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%cd ..\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from tonelocator.tonelocator import detection, conf_matrix\n",
    "from tonelocator.tonelocator.colorizer import colorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17a711",
   "metadata": {},
   "source": [
    "### Create array of image file names and list of photos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859391a",
   "metadata": {},
   "source": [
    "Next, create an array that lists the file names of all the photos you want to run the tonelocator complexion detection methods on. \n",
    "\n",
    "Replace 'folder' below with the file path to the folder your photos are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73669d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tonelocator/example/photos/examples_unprocessed/a_01.jpg'\n",
      " 'tonelocator/example/photos/examples_unprocessed/a_03.jpg'\n",
      " 'tonelocator/example/photos/examples_unprocessed/a_02.jpg'\n",
      " 'tonelocator/example/photos/examples_unprocessed/a_05.jpg'\n",
      " 'tonelocator/example/photos/examples_unprocessed/a_04.jpg']\n",
      "['a_01.jpg' 'a_03.jpg' 'a_02.jpg' 'a_05.jpg' 'a_04.jpg']\n"
     ]
    }
   ],
   "source": [
    "#TODO: replace with the correct folder and a set of unprocessed photos\n",
    "examplefolder = 'tonelocator/example/photos/examples_unprocessed'\n",
    "imgpaths = []\n",
    "imgnames = []\n",
    "for file in os.listdir(examplefolder):\n",
    "    if not file.startswith('.'):\n",
    "        imgpaths.append(os.path.join(examplefolder, file))\n",
    "        imgnames.append(file)\n",
    "imgpaths = np.array(imgpaths)\n",
    "imgnames = np.array(imgnames)\n",
    "print(imgpaths)\n",
    "print(imgnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ec956",
   "metadata": {},
   "source": [
    "### Pre-process photos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ae474",
   "metadata": {},
   "source": [
    "Next, pre-process the photos into three sets of files: \n",
    "1. the color photos that we'll use to detect the \"true\" color composition of the photos \n",
    "2. the grayscale photos that we'll use to test our B&W Monk Scale detection methods on\n",
    "3. colorized versions of the grayscale photos that we'll used to test B&W Monk Scale detection method 2\n",
    "\n",
    "The **preprocess** module crops the photos and has an option to convert them to grayscale. The **colorizer** module is used to colorize B&W photos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b5807f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: tonelocator/example/photos/color: File exists\n",
      "mkdir: tonelocator/example/photos/grayscale: File exists\n",
      "mkdir: tonelocator/example/photos/colorized: File exists\n"
     ]
    }
   ],
   "source": [
    "# Create subfolders to contain preprocessed color photos,\n",
    "# B&W versions of those photos, and colorized versions\n",
    "# of the B&W photos\n",
    "folder = 'tonelocator/example/photos'\n",
    "!mkdir $folder/color\n",
    "!mkdir $folder/grayscale\n",
    "!mkdir $folder/colorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2119a423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tonelocator/example/photos/grayscale/a_01.jpg'\n",
      " 'tonelocator/example/photos/grayscale/a_03.jpg'\n",
      " 'tonelocator/example/photos/grayscale/a_02.jpg'\n",
      " 'tonelocator/example/photos/grayscale/a_05.jpg'\n",
      " 'tonelocator/example/photos/grayscale/a_04.jpg']\n",
      "['a_01.jpg', 'a_03.jpg', 'a_02.jpg', 'a_05.jpg', 'a_04.jpg']\n",
      "['tonelocator/example/photos/color/a_01.jpg'\n",
      " 'tonelocator/example/photos/color/a_03.jpg'\n",
      " 'tonelocator/example/photos/color/a_02.jpg'\n",
      " 'tonelocator/example/photos/color/a_05.jpg'\n",
      " 'tonelocator/example/photos/color/a_04.jpg']\n",
      "['a_01.jpg' 'a_03.jpg' 'a_02.jpg' 'a_05.jpg' 'a_04.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess color images and save one set in color and one set in B&W \n",
    "# TODO: add code to save set of preprocessed pics in respective folders (color & grayscale)\n",
    "#preprocess(i) for i in arr\n",
    "#etc\n",
    "\n",
    "#RETURN: \n",
    "#arr_color\n",
    "#arr_grayscale\n",
    "\n",
    "imgpaths_gray = []\n",
    "imgnames_gray = []\n",
    "for file in os.listdir(folder + '/grayscale'):\n",
    "    if not file.startswith('.'):\n",
    "        imgpaths_gray.append(os.path.join(folder + '/grayscale', file))\n",
    "        imgnames_gray.append(file)\n",
    "imgpaths_gray = np.array(imgpaths_gray)\n",
    "print(imgpaths_gray)\n",
    "print(imgnames_gray)\n",
    "\n",
    "imgpaths_color = []\n",
    "imgnames_color = []\n",
    "for file in os.listdir(folder + '/color'):\n",
    "    if not file.startswith('.'):\n",
    "        imgpaths_color.append(os.path.join(folder + '/color', file))\n",
    "        imgnames_color.append(file)\n",
    "imgpaths_color = np.array(imgpaths_color)\n",
    "imgnames_color = np.array(imgnames_color)\n",
    "print(imgpaths_color)\n",
    "print(imgnames_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae64994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tonelocator/example/photos/colorized/a_01.jpg\n",
      "done with colorizea_01.jpg\n",
      "tonelocator/example/photos/colorized/a_03.jpg\n",
      "done with colorizea_03.jpg\n",
      "tonelocator/example/photos/colorized/a_02.jpg\n",
      "done with colorizea_02.jpg\n",
      "tonelocator/example/photos/colorized/a_05.jpg\n",
      "done with colorizea_05.jpg\n",
      "tonelocator/example/photos/colorized/a_04.jpg\n",
      "done with colorizea_04.jpg\n",
      "['tonelocator/example/photos/colorized/a_01.jpg'\n",
      " 'tonelocator/example/photos/colorized/a_03.jpg'\n",
      " 'tonelocator/example/photos/colorized/a_02.jpg'\n",
      " 'tonelocator/example/photos/colorized/a_05.jpg'\n",
      " 'tonelocator/example/photos/colorized/a_04.jpg']\n",
      "['a_01.jpg' 'a_03.jpg' 'a_02.jpg' 'a_05.jpg' 'a_04.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Colorize each grayscale and save in 'colorized' output folder\n",
    "for pic in imgnames:\n",
    "    \"\"\"\n",
    "    Loop that will run through every file in the input folder, colorize them, and save the colorized image to the output folder.\n",
    "    \"\"\"\n",
    "    imgpath = folder + \"/grayscale/\" + pic\n",
    "    outpath = folder + \"/colorized/\" + pic\n",
    "    print(outpath)\n",
    "    image, colorized = colorizer.colorize_image(imgpath)\n",
    "    print('done with colorize' + pic)\n",
    "    data=cv2.imencode('.png', colorized)[1].tobytes()\n",
    "    cv2.imwrite(outpath, colorized)\n",
    "\n",
    "imgpaths_colorized = []\n",
    "imgnames_colorized = []\n",
    "for file in os.listdir(folder + '/colorized'):\n",
    "    if not file.startswith('.'):\n",
    "        imgpaths_colorized.append(os.path.join(folder + '/colorized', file))\n",
    "        imgnames_colorized.append(file)\n",
    "imgpaths_colorized = np.array(imgpaths_colorized)\n",
    "imgnames_colorized = np.array(imgnames_colorized)\n",
    "print(imgpaths_colorized)\n",
    "print(imgnames_colorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a547a10d",
   "metadata": {},
   "source": [
    "### Detect Monk scale based on color photos - the 'true' result we'll compare our detection methods to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f037621",
   "metadata": {},
   "source": [
    "Next, use the **complexion_detection** function to detect the color composition of the color photos. This is the 'true' result we'll use as a baseline to compare against the two methods of detecting complexion from B&W photos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17d525ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2     3     4     5     6     7     8    9     picid\n",
      "0  0.0  0.0  0.0  0.00  0.06  0.02  0.02  0.02  0.00  0.0  a_01.jpg\n",
      "1  0.0  0.0  0.0  0.01  0.12  0.02  0.03  0.01  0.01  0.0  a_03.jpg\n",
      "2  0.0  0.0  0.0  0.01  0.18  0.03  0.02  0.01  0.00  0.0  a_02.jpg\n",
      "3  0.0  0.0  0.2  0.03  0.05  0.01  0.00  0.00  0.00  0.0  a_05.jpg\n",
      "4  0.0  0.0  0.0  0.00  0.05  0.03  0.04  0.02  0.01  0.0  a_04.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 'picid'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_results = np.array([detection.complexion_detection(i, rounding_places=2, grayscale=False) \n",
    "                                  for i in imgpaths_color])\n",
    "true_df = pd.DataFrame(true_results)\n",
    "true_df['picid'] = imgnames_color\n",
    "# TODO: fix picid to be a numeric identifier\n",
    "print(true_df)\n",
    "true_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70cfee9",
   "metadata": {},
   "source": [
    "### METHOD 1: Detect Monk scale based on B&W versions of color photos and reference to B&W Monk scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d61ff1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1     2     3     4     5     6     7     8     9     picid\n",
      "0  0.0  0.0  0.00  0.00  0.21  0.11  0.08  0.06  0.03  0.01  a_01.jpg\n",
      "1  0.0  0.0  0.07  0.06  0.20  0.08  0.12  0.23  0.07  0.05  a_03.jpg\n",
      "2  0.0  0.0  0.02  0.04  0.35  0.21  0.15  0.10  0.03  0.01  a_02.jpg\n",
      "3  0.0  0.0  0.30  0.06  0.10  0.09  0.11  0.12  0.08  0.02  a_05.jpg\n",
      "4  0.0  0.0  0.00  0.01  0.18  0.27  0.13  0.10  0.09  0.04  a_04.jpg\n"
     ]
    }
   ],
   "source": [
    "m1_results = np.array([detection.complexion_detection(i, \n",
    "                                                      rounding_places=2,\n",
    "                                                     grayscale=True) \n",
    "                                  for i in imgpaths_gray])\n",
    "m1pred_df = pd.DataFrame(m1_results)\n",
    "m1pred_df['picid'] = imgnames_gray\n",
    "print(m1pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f7ac8",
   "metadata": {},
   "source": [
    "### METHOD 2: Detect Monk scale based on colorized photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0d30aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1     2     3     4     5     6     7     8    9     picid\n",
      "0  0.0  0.0  0.00  0.00  0.13  0.02  0.01  0.00  0.00  0.0  a_01.jpg\n",
      "1  0.0  0.0  0.00  0.01  0.14  0.02  0.02  0.03  0.00  0.0  a_03.jpg\n",
      "2  0.0  0.0  0.00  0.01  0.22  0.07  0.03  0.01  0.00  0.0  a_02.jpg\n",
      "3  0.0  0.0  0.02  0.01  0.06  0.01  0.01  0.01  0.01  0.0  a_05.jpg\n",
      "4  0.0  0.0  0.00  0.00  0.11  0.04  0.05  0.02  0.01  0.0  a_04.jpg\n"
     ]
    }
   ],
   "source": [
    "m2_results = np.array([detection.complexion_detection(i, \n",
    "                                                      rounding_places=2,\n",
    "                                                     grayscale=False) \n",
    "                                  for i in imgpaths_colorized])\n",
    "m2pred_df = pd.DataFrame(m2_results)\n",
    "m2pred_df['picid'] = imgnames_colorized\n",
    "print(m2pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6408b5",
   "metadata": {},
   "source": [
    "### Compare effectiveness of each method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a87d2",
   "metadata": {},
   "source": [
    "First, create a confusion matrix for each method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0fa011b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "true needs column named 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconf_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrue_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mm1pred_df\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mplot()\n",
      "File \u001b[0;32m~/tonelocator/tonelocator/conf_matrix.py:30\u001b[0m, in \u001b[0;36mconf_matrix\u001b[0;34m(true, pred)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m reqvars:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m true\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m---> 30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue needs column named \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m v)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred needs column named \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m v)    \n",
      "\u001b[0;31mValueError\u001b[0m: true needs column named 0"
     ]
    }
   ],
   "source": [
    "conf_matrix.conf_matrix(true=true_df, pred=m1pred_df).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb7aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix(true=true_df, pred=m2pred_df).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321ec39",
   "metadata": {},
   "source": [
    "Calculate the MSE for each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80988fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse(true=true_df, pred=m1pred_df, bybin=False))\n",
    "print(mse(true=true_df, pred=m2pred_df, bybin=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf35950",
   "metadata": {},
   "source": [
    "The MSE is higher for X method and the confusion matrix suggests the fit is better for X method - this is probably because XYZ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (v3.9.5:0a7dcbdb13, May  3 2021, 13:17:02) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
