{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fd10a44",
   "metadata": {},
   "source": [
    "# Compare two methods of assessing skin tone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4cbdc",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the **preprocess** and **detection** functions to implement two methods of assessing skin tone in black & white photos -- then, use **conf_matrix**, **mse**, and **OTHER FIT MODULES**? to assess which one worked better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99ad4a",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2944fe3",
   "metadata": {},
   "source": [
    "First, import relevant dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a86bd56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are missing the file \"colorization_release_v2.caffemodel\" Download it and place into your \"model\" folder You can download this file from this location:\n",
      " https://www.dropbox.com/s/dx0qvhhp5hbcx7z/colorization_release_v2.caffemodel?dl=1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(module_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtonelocator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detection, conf_matrix\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtonelocator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m colorizer\n",
      "File \u001b[0;32m~/tonelocator/tonelocator/colorizer/colorizer.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(model): \n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou are missing the file \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolorization_release_v2.caffemodel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownload it and place into your \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m folder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou can download this file from this location:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.dropbox.com/s/dx0qvhhp5hbcx7z/colorization_release_v2.caffemodel?dl=1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mexit\u001b[49m()\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from tonelocator import detection, conf_matrix\n",
    "from tonelocator.colorizer import colorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e74dd9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tonelocator/tonelocator/colorizer/model/colorization_release_v2.caffemodel\n"
     ]
    }
   ],
   "source": [
    "model = r'tonelocator/tonelocator/colorizer/model/colorization_release_v2.caffemodel'\n",
    "model = os.path.join(os.path.dirname(__name__), model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17a711",
   "metadata": {},
   "source": [
    "### Create array of image file names and list of photos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859391a",
   "metadata": {},
   "source": [
    "Next, create an array that lists the file names of all the photos you want to run the tonelocator complexion detection methods on. \n",
    "\n",
    "Replace 'folder' below with the file path to the folder your photos are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73669d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../tonelocator/data/practice_set/.DS_Store'\n",
      " '../tonelocator/data/practice_set/a_01.jpg'\n",
      " '../tonelocator/data/practice_set/a_03.jpg'\n",
      " '../tonelocator/data/practice_set/crop_05.jpg'\n",
      " '../tonelocator/data/practice_set/crop_04.jpg'\n",
      " '../tonelocator/data/practice_set/a_02.jpg'\n",
      " '../tonelocator/data/practice_set/crop_01.jpg'\n",
      " '../tonelocator/data/practice_set/a_05.jpg'\n",
      " '../tonelocator/data/practice_set/crop_03.jpg'\n",
      " '../tonelocator/data/practice_set/crop_02.jpg'\n",
      " '../tonelocator/data/practice_set/a_04.jpg']\n"
     ]
    }
   ],
   "source": [
    "#TODO: replace with the correct folder and a set of unprocessed photos\n",
    "folder = '../tonelocator/data/practice_set'\n",
    "imgpaths = []\n",
    "for file in os.listdir(folder):\n",
    "    imgpaths.append(os.path.join(folder, file))\n",
    "imgpaths = np.array(imgpaths)\n",
    "print(imgpaths)\n",
    "\n",
    "imgnames = []\n",
    "for file in os.listdir(folder):\n",
    "    imgnames.append(file)\n",
    "imgnames = np.array(imgnames)\n",
    "#print(imgnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4ec956",
   "metadata": {},
   "source": [
    "### Pre-process photos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ae474",
   "metadata": {},
   "source": [
    "Next, pre-process the photos into three sets of files: \n",
    "1. the color photos that we'll use to detect the \"true\" color composition of the photos \n",
    "2. the grayscale photos that we'll use to test our B&W Monk Scale detection methods on\n",
    "3. colorized versions of the grayscale photos that we'll used to test B&W Monk Scale detection method 2\n",
    "\n",
    "The **preprocess** module crops the photos and has an option to convert them to grayscale. The **colorizer** module is used to colorize B&W photos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b5807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subfolders to contain preprocessed color photos,\n",
    "# B&W versions of those photos, and colorized versions\n",
    "# of the B&W photos\n",
    "folder = '../example/photos'\n",
    "!mkdir $folder/color\n",
    "!mkdir $folder/grayscale\n",
    "!mkdir $folder/colorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess color images and save one set in color and one set in B&W \n",
    "# TODO: add code to save set of preprocessed pics in respective folders (color & grayscale)\n",
    "preprocess(i) for i in arr\n",
    "etc\n",
    "\n",
    "#RETURN: \n",
    "#arr_color\n",
    "#arr_grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae64994d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tonelocator.colorizer' has no attribute 'colorizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m imgpath \u001b[38;5;241m=\u001b[39m folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m pic\n\u001b[1;32m      7\u001b[0m outpath \u001b[38;5;241m=\u001b[39m folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/grayscale/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m pic\n\u001b[0;32m----> 8\u001b[0m image, colorized \u001b[38;5;241m=\u001b[39m \u001b[43mcolorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolorizer\u001b[49m\u001b[38;5;241m.\u001b[39mcolorize_image(imgpath)\n\u001b[1;32m      9\u001b[0m data\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, colorized)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m     10\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(outpath, colorized)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tonelocator.colorizer' has no attribute 'colorizer'"
     ]
    }
   ],
   "source": [
    "# Colorize each file in loop in input folder and save in output folder\n",
    "for pic in imgnames:\n",
    "    \"\"\"\n",
    "    Loop that will run through every file in the input folder, colorize them, and save the colorized image to the output folder.\n",
    "    \"\"\"\n",
    "    imgpath = folder + \"/\" + pic\n",
    "    outpath = folder + \"/colorized/\" + pic\n",
    "    image, colorized = colorizer.colorize_image(imgpath)\n",
    "    data=cv2.imencode('.png', colorized)[1].tobytes()\n",
    "    cv2.imwrite(outpath, colorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a547a10d",
   "metadata": {},
   "source": [
    "### Detect Monk scale based on color photos - the 'true' result we'll compare our detection methods to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f037621",
   "metadata": {},
   "source": [
    "Next, use the **complexion_detection** function to detect the color composition of the color photos. This is the 'true' result we'll use as a baseline to compare against the two methods of detecting complexion from B&W photos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17d525ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1     2     3     4     5     6     7     8    9        picid\n",
      "0  0.0  0.0  0.00  0.00  0.06  0.02  0.02  0.02  0.00  0.0     a_01.jpg\n",
      "1  0.0  0.0  0.00  0.01  0.12  0.02  0.03  0.01  0.01  0.0     a_03.jpg\n",
      "2  0.0  0.0  0.06  0.01  0.02  0.05  0.01  0.00  0.00  0.0  crop_05.jpg\n",
      "3  0.0  0.0  0.00  0.00  0.16  0.12  0.10  0.03  0.00  0.0  crop_04.jpg\n",
      "4  0.0  0.0  0.00  0.01  0.18  0.03  0.02  0.01  0.00  0.0     a_02.jpg\n",
      "5  0.0  0.0  0.00  0.00  0.35  0.10  0.08  0.04  0.01  0.0  crop_01.jpg\n",
      "6  0.0  0.0  0.20  0.03  0.05  0.01  0.00  0.00  0.00  0.0     a_05.jpg\n",
      "7  0.0  0.0  0.00  0.01  0.36  0.03  0.02  0.01  0.00  0.0  crop_03.jpg\n",
      "8  0.0  0.0  0.00  0.01  0.34  0.09  0.06  0.01  0.00  0.0  crop_02.jpg\n",
      "9  0.0  0.0  0.00  0.00  0.05  0.03  0.04  0.02  0.01  0.0     a_04.jpg\n"
     ]
    }
   ],
   "source": [
    "true_results = np.array([detection.complexion_detection(i, rounding_places=2) \n",
    "                                  for i in files])\n",
    "true_df = pd.DataFrame(true_results)\n",
    "true_df['picid'] = imgnames\n",
    "# TODO: fix picid to be a numeric identifier\n",
    "print(true_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70cfee9",
   "metadata": {},
   "source": [
    "### METHOD 1: Detect Monk scale based on B&W versions of color photos and reference to B&W Monk scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ff1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_results = np.array([detection.complexion_detection(i, \n",
    "                                                      rounding_places=2,\n",
    "                                                     grayscale=True) \n",
    "                                  for i in arr_grayscale])\n",
    "m1pred_df = pd.DataFrame(m1_results)\n",
    "m1pred_df['picid'] = arr_color\n",
    "# TODO: fix picid to be a numeric identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1f7ac8",
   "metadata": {},
   "source": [
    "### METHOD 2: Detect Monk scale based on colorized photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d30aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_results = np.array([detection.complexion_detection(i, \n",
    "                                                      rounding_places=2,\n",
    "                                                     grayscale=False) \n",
    "                                  for i in arr_colorized])\n",
    "m2pred_df = pd.DataFrame(m2_results)\n",
    "m2pred_df['picid'] = arr_colorized\n",
    "# TODO: fix picid to be a numeric identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6408b5",
   "metadata": {},
   "source": [
    "### Compare effectiveness of each method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a87d2",
   "metadata": {},
   "source": [
    "First, create a confusion matrix for each method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix(true=true_df, pred=m1pred_df).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb7aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix(true=true_df, pred=m2pred_df).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9321ec39",
   "metadata": {},
   "source": [
    "Calculate the MSE for each method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80988fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse(true=true_df, pred=m1pred_df, bybin=False))\n",
    "print(mse(true=true_df, pred=m2pred_df, bybin=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf35950",
   "metadata": {},
   "source": [
    "The MSE is higher for X method and the confusion matrix suggests the fit is better for X method - this is probably because XYZ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
